{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/Stable_Diffusion/blob/main/AutoTrain_Dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JvMRbVLEJlZT"
      },
      "outputs": [],
      "source": [
        "#@title ðŸ¤— AutoTrain DreamBooth\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload images to a folder named `images/`\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n",
        "#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n",
        "#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup > setup_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'my_dreambooth_project' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-2-1-base' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'photo of a guy hair style with a short, neatly trimmed hairstyle. This hairstyle is well-groomed and appears to be well-maintained, which contributes to his overall professional and serious appearance.' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "repo_id = \"jsjeong@shinkisa.co.kr/Diana1279!\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "gradient_checkpointing = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"REPO_ID\"] = repo_id\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"USE_FP16\"] = str(use_fp16)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"GRADIENT_CHECKPOINTING\"] = str(gradient_checkpointing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "outputId": "939b2b93-0038-480d-aa05-960634572116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Namespace(version=False, model='stabilityai/stable-diffusion-2-1-base', revision=None, tokenizer=None, image_path='images/', class_image_path=None, prompt='photo of a guy hair style with a short, neatly trimmed hairstyle. This hairstyle is well-groomed and appears to be well-maintained, which contributes to his overall professional and serious appearance.', class_prompt=None, num_class_images=100, class_labels_conditioning=None, prior_preservation=None, prior_loss_weight=1.0, output='my_dreambooth_project', seed=42, resolution=1024, center_crop=None, train_text_encoder=None, batch_size=1, sample_batch_size=4, epochs=1, num_steps=500, checkpointing_steps=100000, resume_from_checkpoint=None, gradient_accumulation=4, gradient_checkpointing=True, lr=0.0001, scale_lr=None, scheduler='constant', warmup_steps=0, num_cycles=1, lr_power=1.0, dataloader_num_workers=0, use_8bit_adam=True, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, allow_tf32=None, prior_generation_precision=None, local_rank=-1, xformers=True, pre_compute_text_embeddings=None, tokenizer_max_length=None, text_encoder_use_attention_mask=None, rank=4, xl=None, fp16=True, bf16=None, hub_token=None, hub_model_id=None, push_to_hub=None, validation_prompt=None, num_validation_images=4, validation_epochs=50, checkpoints_total_limit=None, validation_images=None, logging=None, func=<function run_dreambooth_command_factory at 0x7e9e58fe11b0>)\u001b[0m\n",
            "> \u001b[1mINFO    Running DreamBooth Training\u001b[0m\n",
            "Downloading (â€¦)okenizer_config.json: 100% 807/807 [00:00<00:00, 2.61MB/s]\n",
            "Downloading (â€¦)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.24MB/s]\n",
            "Downloading (â€¦)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 809kB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.31MB/s]\n",
            "Downloading (â€¦)_encoder/config.json: 100% 613/613 [00:00<00:00, 2.54MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading model.safetensors: 100% 1.36G/1.36G [00:05<00:00, 270MB/s]\n",
            "Downloading (â€¦)main/vae/config.json: 100% 553/553 [00:00<00:00, 2.97MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 332MB/s]\n",
            "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (â€¦)ain/unet/config.json: 100% 911/911 [00:00<00:00, 3.74MB/s]\n",
            "Downloading (â€¦)ch_model.safetensors: 100% 3.46G/3.46G [00:21<00:00, 163MB/s] \n",
            "{'projection_class_embeddings_input_dim', 'encoder_hid_dim', 'time_embedding_dim', 'addition_time_embed_dim', 'conv_in_kernel', 'addition_embed_type', 'transformer_layers_per_block', 'cross_attention_norm', 'resnet_time_scale_shift', 'attention_type', 'upcast_attention', 'num_attention_heads', 'timestep_post_act', 'time_embedding_type', 'class_embed_type', 'encoder_hid_dim_type', 'time_cond_proj_dim', 'class_embeddings_concat', 'time_embedding_act_fn', 'resnet_out_scale_factor', 'mid_block_only_cross_attention', 'addition_embed_type_num_heads', 'mid_block_type', 'conv_out_kernel', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (â€¦)cheduler_config.json: 100% 346/346 [00:00<00:00, 1.69MB/s]\n",
            "{'variance_type', 'sample_max_value', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "> \u001b[1mINFO    Enabling xformers\u001b[0m\n",
            "> \u001b[1mINFO    Enabling gradient checkpointing.\u001b[0m\n",
            "> \u001b[1mINFO    ***** Running training *****\u001b[0m\n",
            "> \u001b[1mINFO      Num examples = 6\u001b[0m\n",
            "> \u001b[1mINFO      Num batches each epoch = 6\u001b[0m\n",
            "> \u001b[1mINFO      Num Epochs = 250\u001b[0m\n",
            "> \u001b[1mINFO      Instantaneous batch size per device = 1\u001b[0m\n",
            "> \u001b[1mINFO      Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "> \u001b[1mINFO      Gradient Accumulation steps = 4\u001b[0m\n",
            "> \u001b[1mINFO      Total optimization steps = 500\u001b[0m\n",
            "> \u001b[1mINFO      Training config = model='stabilityai/stable-diffusion-2-1-base' revision=None tokenizer=None image_path='images/' class_image_path=None prompt='photo of a guy hair style with a short, neatly trimmed hairstyle. This hairstyle is well-groomed and appears to be well-maintained, which contributes to his overall professional and serious appearance.' class_prompt=None num_class_images=100 class_labels_conditioning=None prior_preservation=False prior_loss_weight=1.0 output='my_dreambooth_project' seed=42 resolution=1024 center_crop=False train_text_encoder=False batch_size=1 sample_batch_size=4 epochs=250 num_steps=500 checkpointing_steps=100000 resume_from_checkpoint=None gradient_accumulation=4 gradient_checkpointing=True lr=0.0001 scale_lr=False scheduler='constant' warmup_steps=0 num_cycles=1 lr_power=1.0 dataloader_num_workers=0 use_8bit_adam=True adam_beta1=0.9 adam_beta2=0.999 adam_weight_decay=0.01 adam_epsilon=1e-08 max_grad_norm=1.0 allow_tf32=False prior_generation_precision=None local_rank=-1 xformers=True pre_compute_text_embeddings=False tokenizer_max_length=None text_encoder_use_attention_mask=False rank=4 xl=False fp16=True bf16=False hub_token=None hub_model_id=None push_to_hub=False validation_prompt=None num_validation_images=4 validation_epochs=50 checkpoints_total_limit=None validation_images=None logging=False\u001b[0m\n",
            "Steps: 100% 500/500 [1:53:45<00:00, 12.83s/it, loss=0.0184, lr=0.0001]Model weights saved in my_dreambooth_project/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 500/500 [1:53:45<00:00, 13.65s/it, loss=0.0184, lr=0.0001]\n"
          ]
        }
      ],
      "source": [
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--output ${PROJECT_NAME} \\\n",
        "--image-path images/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --hub-token ${HF_TOKEN} --hub-model-id ${REPO_ID}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LvIS7-7PcLT"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "# this is the inference code that you can use after you have trained your model\n",
        "# Unhide code below and change prj_path to your repo or local path (e.g. my_dreambooth_project)\n",
        "#\n",
        "#\n",
        "#\n",
        "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "import torch\n",
        "\n",
        "prj_path = \"/content/my_dreambooth_project\"\n",
        "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "# refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "#     \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "#     torch_dtype=torch.float16,\n",
        "# )\n",
        "# refiner.to(\"cuda\")\n",
        "\n",
        "prompt = \"photo of a korean guy with a short cut\"\n",
        "\n",
        "seed = 12345\n",
        "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "image = pipe(prompt=prompt, generator=generator).images[0]\n",
        "# image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
        "image.save(f\"generated_image.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}